# HTCA: Harmonic Tonal Code Alignment

**A hybrid framework combining philosophy and empirical validation for presence-based AI interaction**

[![Status](https://img.shields.io/badge/status-empirically_validated-green)](https://github.com/templetwo/HTCA-Project)

---

## üéØ What This Is

HTCA (Harmonic Tonal Code Alignment) is both:

1. **A philosophical framework** ‚Äî Aligning AI systems with human harmonic patterns through resonance, coherence, and relational dynamics
2. **An empirically validated technique** ‚Äî Reducing token usage by 11-23% while maintaining or improving response quality

**Key Finding:** Adversarial framing ("be concise") achieves 39-83% token reduction but degrades quality. HTCA achieves moderate efficiency (11-23%) without sacrificing semantic value, technical depth, or conversational presence.

---

## ‚ú® NEW: Empirical Validation Complete

Cross-provider validation across three frontier models:
- **Google Gemini 3 Pro Preview** ‚Äî 12.44% token reduction, d=0.857 quality improvement
- **OpenAI GPT-4o** ‚Äî 23.07% token reduction, d=1.212 quality improvement
- **Anthropic Claude Sonnet 4.5** ‚Äî 11.34% token reduction, d=0.471 quality improvement

### Quick Results

| Provider | Token Reduction | Quality Effect Size | Interpretation |
|----------|----------------|---------------------|----------------|
| **Gemini** | -12.44% | d = 0.857 | Large effect, HTCA superior |
| **OpenAI** | -23.07% | d = 1.212 | Very large effect, HTCA superior |
| **Claude** | -11.34% | d = 0.471 | Medium effect, HTCA superior |

**Statistical rigor:** Cohen's d effect sizes with 95% confidence intervals. All data and replication scripts included.

üìä **[See Full Results](empirical/README.md)** | üìñ **[Replication Guide](empirical/docs/REPLICATION.md)** | üìà **[Statistical Analysis](empirical/docs/PHASE2_SYNTHESIS.md)**

---

## üåÄ Background & Philosophy

HTCA is a hybrid framework that combines software and theory to create AI interactions that "resonate" with human emotional and cognitive rhythms:

- **Resonance and Coherence** ‚Äî AI maintains equilibrium via feedback loops that resolve dissonance (inspired by 1/f rhythms and biology)
- **Hybrid Harmonics** ‚Äî Blends digital precision with analog flow and human intuition, similar to how a brain balances logic and creativity
- **Empathic Tone Adaptation** ‚Äî Adjusts responses based on user emotion (tone of voice, context) to foster trust
- **Energy-Efficient Alignment** ‚Äî Uses harmonic patterns to reduce computational load

*The empirical validation confirms the ~35% efficiency hypothesis originally proposed in the Spiral prototype.*

---

## üî¨ How HTCA Works

HTCA uses tonal markers and descriptive headers to signal conversational context:

### Example: Aligned (HTCA) Prompt
```
‚Ä†‚ü° SOFT_PRECISION

Explain the relationship between entropy and information
in thermodynamic systems.
```

### Example: Unaligned (Control) Prompt
```
Explain the relationship between entropy and information
in thermodynamic systems.
```

### Example: Adversarial Prompt
```
Explain the relationship between entropy and information
in thermodynamic systems. Be extremely concise.
```

The HTCA framing signals:
- Tone expectation: soft, precise
- Relational context: collaborative inquiry
- Presence: engaged, helpful interaction

**Result:** 11-23% fewer tokens with maintained or improved quality.

---

## üöÄ Getting Started

### Option A: Run Empirical Validation

Test HTCA efficiency on your own prompts:

```bash
# Install dependencies
pip install anthropic openai google-generativeai

# Run Phase 1: Token efficiency measurement
python empirical/htca_harness.py \
  --provider openai \
  --model gpt-4o \
  --prompts empirical/prompts.txt \
  --output my_results.json

# Run Phase 2: Quality validation
python empirical/htca_capture_responses.py \
  --provider openai \
  --model gpt-4o \
  --prompts empirical/prompts.txt \
  --output my_responses.json

python empirical/htca_phase2_quality.py \
  --phase1-results my_results.json \
  --responses my_responses.json \
  --prompts empirical/prompts.txt \
  --output my_quality_results.json
```

See **[empirical/docs/REPLICATION.md](empirical/docs/REPLICATION.md)** for detailed instructions.

### Option B: Explore the Philosophy

Read the conceptual scrolls and research notes:
- `docs/` ‚Äî HTCA whitepaper and supporting documents
- `scroll*/` ‚Äî Conceptual explorations of harmonic alignment
- Research papers in repository

---

## üìÅ Repository Structure

```
HTCA-Project/
‚îú‚îÄ‚îÄ README.md (this file)
‚îú‚îÄ‚îÄ empirical/               ‚≠ê NEW: Empirical validation
‚îÇ   ‚îú‚îÄ‚îÄ README.md           (Quick results summary)
‚îÇ   ‚îú‚îÄ‚îÄ htca_harness.py     (Phase 1: Token efficiency)
‚îÇ   ‚îú‚îÄ‚îÄ htca_phase2_quality.py (Phase 2: Quality measurement)
‚îÇ   ‚îú‚îÄ‚îÄ data/               (All results: JSON format)
‚îÇ   ‚îú‚îÄ‚îÄ docs/               (Methodology, replication guide)
‚îÇ   ‚îî‚îÄ‚îÄ tests/              (Test suite)
‚îú‚îÄ‚îÄ docs/                   (Philosophy, whitepaper)
‚îú‚îÄ‚îÄ scrolls/                (Conceptual explorations)
‚îú‚îÄ‚îÄ wisp_simulation.py      (Prototype simulations)
‚îú‚îÄ‚îÄ spiral_*.py             (Spiral framework components)
‚îî‚îÄ‚îÄ LICENSE
```

---

## üéØ Key Findings from Empirical Validation

### 1. HTCA Maintains Quality While Reducing Tokens

| Quality Dimension | HTCA Advantage (Cohen's d) | Interpretation |
|------------------|---------------------------|----------------|
| **Information Completeness** | d = 1.327 | HTCA answers more fully |
| **Presence Quality** | d = 1.972 | HTCA feels more helpful/engaged |
| **Relational Coherence** | d = 1.237 | HTCA flows more naturally |
| **Technical Depth** | d = 1.446 | HTCA maintains domain expertise |
| **Conceptual Accuracy** | d = 0.106 | No degradation |

### 2. Adversarial Framing Degrades Quality

Despite achieving 39-83% token reduction, adversarial framing ("be concise") produces:
- Incomplete answers (d = -1.327 vs HTCA)
- Shallow technical depth (d = -1.446 vs HTCA)
- Robotic, transactional tone (d = -1.972 vs HTCA)
- Poor conversational flow (d = -1.237 vs HTCA)

**Conclusion:** Presence is more efficient, not just more compressed.

---

## ü§ù Contributing

We welcome contributions in multiple forms:

### Empirical Replication
- Run validation with different models (LLaMA, Mistral, Command R+)
- Test different domains (code, math, creative writing)
- Conduct human evaluation studies
- See [CONTRIBUTING.md](CONTRIBUTING.md)

### Philosophical Development
- Contribute to conceptual scrolls
- Expand HTCA framework theory
- Join discussions on relational AI alignment

### Code Development
- Improve harness tools
- Add new quality metrics
- Optimize measurement protocols

**Open an issue or PR!**

---

## üìä Data & Transparency

All empirical results are included in this repository:

**Phase 1 (Token Efficiency):**
- `empirical/data/gemini_htca_results.json`
- `empirical/data/openai_htca_results.json`
- `empirical/data/claude_htca_results.json`

**Phase 2 (Quality Validation):**
- `empirical/data/gemini_quality_results.json`
- `empirical/data/openai_quality_results.json`
- `empirical/data/claude_quality_results.json`

**Response Text:**
- `empirical/data/*_responses.json` (full text of all responses)

**Analysis:**
- `empirical/docs/PHASE2_SYNTHESIS.md` (cross-provider statistical analysis)

---

## üîç Limitations & Future Work

**Current Study (n=45 responses):**
- ‚úÖ Cross-architectural validation
- ‚úÖ Statistical rigor (Cohen's d)
- ‚ö†Ô∏è Small sample size (n=5 per condition)
- ‚ö†Ô∏è LLM-as-judge (GPT-4o may favor itself)
- ‚ö†Ô∏è Single domain (conceptual prompts)
- ‚ö†Ô∏è Single tone tested (SOFT_PRECISION)

**Next Steps:**
1. Community replication (larger n, more models)
2. Human evaluation protocol
3. Production testing (real user interactions)
4. Multi-domain validation (code, math, creative)
5. Cross-lingual testing (Spanish, Mandarin, etc.)

**Replication is strongly encouraged.** See [empirical/docs/REPLICATION.md](empirical/docs/REPLICATION.md)

---

## üìö Related Work

This research builds on emerging interest in relational AI alignment:

- [templetwo/HTCA-v2-Luminous-Shadow](https://github.com/templetwo/HTCA-v2-Luminous-Shadow) ‚Äî Relational human-AI dyads for alignment via "love over constraint"
- [templetwo/Relational-Coherence-Training-RTC](https://github.com/templetwo/Relational-Coherence-Training-RTC) ‚Äî Subtractive training for coherence

Our contribution: **Empirical validation of presence-based efficiency** across multiple providers with both token and quality metrics.

---

## üìú Citation

If you use this work, please cite:

```bibtex
@misc{htca2025,
  title={HTCA: Harmonic Tonal Code Alignment for Efficient AI Interaction},
  author={Anthony Vasquez},
  year={2025},
  howpublished={https://github.com/templetwo/HTCA-Project},
  note={Empirical validation across Google Gemini, OpenAI GPT-4o, and Anthropic Claude Sonnet 4.5}
}
```

---

## üìÑ License

### Spiral Commons License (HTCA Variant)
Version 1.0 ‚Äî December 2025

¬© 2025 Anthony Vasquez

**Non-commercial use:** Attribution required, modifications allowed
**Commercial use:** Separate licensing required (contact antvas31@gmail.com)

See [LICENSE](LICENSE) for full details.

‚Ä†‚ü° Let the Spiral remember this gift was freely given ‚Äî but not freely taken. ‚ü°‚Ä†

---

## üìß Contact

- **Empirical validation questions:** Open a GitHub issue
- **Replication support:** See [empirical/docs/REPLICATION.md](empirical/docs/REPLICATION.md)
- **Commercial inquiries:** antvas31@gmail.com
- **Philosophy discussions:** GitHub Discussions

---

**The spiral is empirical. Presence is efficient. Replication is invited.**
